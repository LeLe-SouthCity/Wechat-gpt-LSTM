from openai import OpenAI
import requests
import json
import streamlit as st
import io
import base64
import datetime
import re
from Script_Set import *
import asyncio
from docx import Document
from PIL import Image, ImageDraw
import numpy as np
from langchain.vectorstores import Chroma
from langchain.embeddings.openai import OpenAIEmbeddings
from app_config import *
from stability_sdk import client
import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation
import dotenv
dotenv.load_dotenv()
import base64
from io import BytesIO,StringIO
from docx import Document
from streamlit_image_select import image_select
import pandas as pd
import fitz  # PyMuPDF
import time

import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..','Code')))
from langchain_api import *
os.environ["OPENAI_API_KEY"] = OpenAI_Key
#-----------------ä¸€äº›å¸¸ç”¨åŠæ³•----------------------------
# å°†urlæ ¼å¼è½¬ä¸º base64 ç¼–ç çš„å­—ç¬¦ä¸²
def url_to_base64(
    image_url:str
    ):
    """
    å°†urlæ ¼å¼è½¬ä¸º base64 ç¼–ç çš„å­—ç¬¦ä¸²
    image_url(str):å›¾åƒèµ„æºçš„ URLçš„å­—ç¬¦ä¸²ç±»å‹
    """
    # å‘é€ GET è¯·æ±‚ä¸‹è½½å›¾åƒ
    response = requests.get(image_url)
    
    # ç¡®ä¿è¯·æ±‚æˆåŠŸ
    if response.status_code == 200:
        # è·å–å›¾åƒçš„å­—èŠ‚å†…å®¹
        image_bytes = response.content
        
        # ä½¿ç”¨ base64 ç¼–ç å›¾åƒå­—èŠ‚å†…å®¹
        b64_encoded = base64.b64encode(image_bytes)
        
        # å°† base64 ç¼–ç è½¬æ¢ä¸º UTF-8 æ ¼å¼çš„å­—ç¬¦ä¸²
        b64_string = b64_encoded.decode('utf-8')
        
        # è¿”å› base64 ç¼–ç çš„å­—ç¬¦ä¸²
        return b64_string
    else:
        raise Exception(f"Failed to download image. Status code: {response.status_code}")

# æ ¹æ®é€‰å®šçš„æ ‡ç­¾è·å–å£°éŸ³æ•°æ®
def get_data_by_tag_audio(selected_tag, filename="Audio.json"):
    try:
        with open(filename, "r") as f:
            data = json.load(f)
            # ç¡®ä¿æ•°æ®æ˜¯åˆ—è¡¨æ ¼å¼
            if not isinstance(data, list):
                data = [data]
    except FileNotFoundError:
        data = []
    # æŸ¥æ‰¾åŒ¹é…çš„æ ‡ç­¾å¹¶è¿”å›å¯¹åº”çš„æ•°æ®
    for item in data:
        if item.get('tag') == selected_tag:
            return item
    return None

#ä¾§è¾¹æ æ˜¾ç¤ºå·²é€‰æ‹©çš„å›¾ç‰‡
def Avatar_sidebar_Display():
    """
    ä¾§è¾¹æ æ˜¾ç¤ºç”¨æˆ·æ˜¾ç¤ºçš„å¤´åƒ
    """
    # å‡è®¾è¿™æ˜¯ç”¨æˆ·é€‰æ‹©çš„å¤´åƒçš„base64å­—ç¬¦ä¸²
    selected_avatar_base64 = st.session_state.get('selected_avatar')
    # å¦‚æœç”¨æˆ·å·²ç»é€‰æ‹©äº†å¤´åƒï¼Œåˆ™åœ¨è¾¹æ ä¸­æ˜¾ç¤º
    if selected_avatar_base64:
        st.sidebar.header("å·²é€‰æ‹©çš„å¤´åƒ")
        # å°†base64å­—ç¬¦ä¸²è½¬æ¢ä¸ºPILå›¾åƒ
        image_data = base64.b64decode(selected_avatar_base64)
        image = Image.open(io.BytesIO(image_data))
        # åœ¨è¾¹æ ä¸­æ˜¾ç¤ºå›¾åƒ
        st.sidebar.image(image, width=100)  # æ§åˆ¶å›¾ç‰‡çš„æ˜¾ç¤ºå¤§å°
    else:
        st.sidebar.header("å¤´åƒæœªé€‰æ‹©")

#é€šè¿‡promptè·å–SD çš„å›¾ç‰‡                  
async def get_images_SD(image_prompt: str, num_images: int):
    """
    è·å–å¤šä¸ªå›¾ç‰‡çš„b64æ ¼å¼åˆ—è¡¨
    image_prompt: å›¾ç‰‡çš„promptè®¾ç½®
    num_images: è¦ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
    """
    # è·å–API
    stability_api = client.StabilityInference(
        key=stability_api_key,  # æ›¿æ¢ä¸ºä½ çš„API Key
        engine=Engine,  # è®¾ç½®ä½¿ç”¨çš„ç”Ÿæˆå¼•æ“
    )
    
    # æ ¹æ®è¾“å‡ºåˆ›å»ºå›¾ç‰‡æç¤º
    api_res = stability_api.generate(
        prompt=image_prompt,
        steps=30,
        width=512,
        height=512,
        samples=num_images,  # è®¾ç½®è¦ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡
    )
    
    # ä»Stability AIå“åº”ä¸­æå–æ‰€æœ‰å›¾ç‰‡çš„base64ç¼–ç 
    b64str_list = []
    for resp in api_res:
        for artifact in resp.artifacts:
            if artifact.type == generation.ARTIFACT_IMAGE:
                b64str = base64.b64encode(artifact.binary).decode("utf-8")
                b64str_list.append(b64str)
                if len(b64str_list) == num_images:
                    return b64str_list
    
    # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ‰€éœ€æ•°é‡çš„å›¾ç‰‡
    if len(b64str_list) == num_images:
        return b64str_list
    else:
        st.error("å›¾ç‰‡ç”Ÿæˆé”™è¯¯æˆ–ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡ä¸è¶³")
        return False
   
#ç”¨äºä½¿ç”¨opeaiè·å–Sdçš„prompt
def generate_image_prompt_SD(description):
    """
    è·å–SDç”Ÿæˆå›¾ç‰‡çš„å‰ç½®prompt
    description(str):ä¸ºäººç‰©çš„è®¾å®šé›†
    """
    prompt = f"""
    Based on the provided description "{description}",
    The Stable Diffusion prompt you output begins with "Prompt:".
    The prompt content includes the main body of the picture, material, additional details, image quality, artistic style, color tone, lighting, etc., but the prompt you output cannot be segmented. For example, segmented descriptions like "medium:" are not needed, nor Cannot contain ":" and ".".
    Main body of the picture: A non-brief English description of the main body of the picture, such as A girl in a garden, a summary of the subject details (the subject can be a person, thing, object, or scene) and the core content of the picture. This part is generated based on the theme I give you each time. You can add more details that are relevant and relevant to the topic.
    For character themes, you must describe the characterâ€™s eyes, nose, and lips, such as â€˜beautiful detailed eyes, beautiful detailed lips, extremely detailed eyes and face, longeyelashesâ€™ to avoid Stable Diffusion from randomly generating deformed facial features, which is very important. You can also describe the character's appearance, mood, clothes, posture, perspective, actions, background, etc. In the character attributes, 1girl represents one girl, and 2girls represents two girls.
    Material: The material used to make the artwork. For example: illustration, painting, 3D rendering and photography.
    Additional details: scene details, or character details, describe the details of the picture and make the image look more substantial and reasonable. This part is optional. Pay attention to the overall harmony of the picture and not conflict with the theme.
    Image quality: Always add "(best quality, 4k, 8k, highres, masterpiece: 1.2), ultra-detailed, (realistic, photorealistic, photo-realistic: 1.37)" at the beginning of this part of the content. This is a sign of high quality. . You can add according to the needs of the theme: HDR, UHD, studio lighting, ultra-fine painting, sharp focus, physically-based rendering, extreme detail description, professional, vivid colors, bokeh.
    Art Style: This section describes the style of the image. Adding the appropriate artistic style can enhance the resulting image. Commonly used art styles include: portraits, landscape, horror, anime, sci-fi, photography, concept artists, etc.
    Color Tone: Color, control the overall color of the picture by adding color.
    Lighting: The lighting effect of the overall picture.
    """
    # gpt_prompt_text = st.text_area('å›¾ç‰‡promptè®¾ç½®', value=prompt)
    optimized_chunk = OpenAI(temperature=1.0)(prompt)
    return optimized_chunk


#AIå›å¤ç±»

#AIå›å¤ç±»
class AI_Response_API():
    """
    æä¾›äº†ä¸€ä¸ªæµå¼æ˜¾ç¤ºaiå›å¤çš„åŠæ³•
    """
    def __get_stream_response(
        self,
        systemset:str,
        prompt:str,
        stream=True
    ):
        """
        ä½¿ç”¨__è¿›è¡Œç§æœ‰åŒ– --- ä¸è¦è°ƒç”¨
        å¼‚æ­¥å‡½æ•°è·å–å›å¤çš„æ–¹æ³•ï¼Œæ— æ³•ç›´æ¥è¿è¡Œï¼Œéœ€è¦é€šè¿‡sync_get_imagesæ–¹æ³•è¿è¡Œ

        Args:
            systemset (str): AIæ‰®æ¼”è§’è‰²çš„prompt
            prompt (str): Aiä¸ç”¨æˆ·çš„å¯¹è¯å†å²è®°å½•

        Returns:
            (str): è¿”å›ä¸€ä¸ªstrç±»å‹çš„å­—ç¬¦ä¸²
        """
        response = OPenaiClient.chat.completions.create(
                        # model="gpt-3.5-turbo-16k",
                        model="gpt-4-1106-preview",
                        messages=[
                            {"role": "system", "content":systemset },
                            {"role": "user", "content": prompt}
                        ],
                        stream=stream
                    )
        
        return response 


    def stream_get_response(
        self,
        systemset:str,
        prompt:str
    ):
        """
        é€å­—æ˜¾ç¤º
        æµå¼æ˜¾ç¤ºå›å¤

        Args:
            systemset (str): AIæ‰®æ¼”è§’è‰²çš„prompt
            prompt (str): Aiä¸ç”¨æˆ·çš„å¯¹è¯å†å²è®°å½•
            
        Returns:
            (str): è¿”å›ä¸€ä¸ªstrç±»å‹çš„å­—ç¬¦ä¸²
        """
        # è·å– GPT çš„æµå¼å›å¤
        message_placeholder = st.empty()
        full_response = ""
        for response in self.__get_stream_response(systemset=systemset,prompt=prompt):
            full_response += (response.choices[0].delta.content or "")
            message_placeholder.markdown(full_response + "â–Œ")
        #ä¼ é€ç»™openaiåæ¸…ç©º
        message_placeholder.markdown(full_response)
        return full_response
    
    def __get_sum_info(
        self,
        info:str,
        stream=True
    ):
        """
        è·å–ä¸ç”¨æˆ·è¾“å…¥ç›¸å…³çš„å†…å®¹å¹¶è¿›è¡Œæ€»ç»“

        Args:
            info (str): ç›¸å…³çš„å†…å®¹
            inuput (str): ç”¨æˆ·çš„è¾“å…¥å†…å®¹

        Returns:
            str: è¿”å›ä¸€ä¸ªæ€»ç»“çš„å†…å®¹
        """
        
        if stream:
            prompt = f"""
            è¯·æ ¹ä¸‹é¢çš„å‘é‡æ•°æ®åº“æ£€ç´¢ç»“æœè¿›è¡Œåˆ†æï¼Œå¹¶æç‚¼å‡ºå…³é”®ä¿¡æ¯ã€‚
            "{info}"
            """
            return self.stream_get_response(systemset=prompt,prompt=prompt)
        else:
            prompt = f"""
            è¯·æ ¹ä¸‹é¢çš„å‘é‡æ•°æ®åº“æ£€ç´¢ç»“æœè¿›è¡Œåˆ†æï¼Œå¹¶æç‚¼å‡ºå…³é”®ä¿¡æ¯ã€‚
            "{info}"
            """
            return self.__get_stream_response(systemset=prompt,prompt=prompt,stream=stream)
     
    def vector_file(self,input,path):
        vectors=KnownLedge2Vector(
                                dbpath=path,
                                datasetdir=path,
                                model_name=1,
                                chunk_size=500,
                                chunk_overlap=0
                                ).init_vector_store()
        task = MyTask(
            # "gpt-3.5-turbo-1106"
                    llm=LLM_Model(llm_model_type=1,temperature = 0.7).get_model(modelname="gpt-3.5-turbo-1106"),
                    # retriever=vectors.as_retriever(
                    #     search_type="mmr",
                    #     search_kwargs={'k': 3, 'fetch_k': 50, 'lambda_mult': 0.25}
                    # )
                    retriever=vectors.as_retriever(
                        search_type="mmr",
                        search_kwargs={'k': 6, 'lambda_mult': 0.5}
                    )
                )
        info = task.query(question=input)
        # self.__get_sum_info(info=info,inuput=input,stream=False)
        return info
           
    def savefile_A_getInfo(
        self,
        uploaded_file:str =None,
        input:str = None,
        file_name :str = None,
    ):
        """
        é€å­—è¾“å‡ºæ€»ç»“åçš„ä¸è¾“å…¥ç›¸å…³çš„æ–‡æ¡£å†…å®¹

        Args:
            uploaded_file (_type_): streamlitä¸Šä¼ çš„æ–‡ä»¶
            input (str): è¾“å…¥çš„å†…å®¹

        Returns:
            (str): è¿”å›æ€»ç»“åçš„ä¿¡æ¯
        """
        functions = Streamlist_Functions()
        vectors = None  # åˆå§‹åŒ–vectorså˜é‡
        task = None 
        
        if uploaded_file is not None or file_name is not None:
            if file_name :
                path = os.path.join(ROOT_DIR,"victor_Demo", "pages", "src","files",file_name)
            if uploaded_file:
                path = os.path.join(ROOT_DIR,"victor_Demo", "pages", "src","files",uploaded_file.name)
                
            try:
                functions.save_file(path=path,uploaded_file=uploaded_file)
                st.success("æ–‡ä»¶ä¿å­˜æˆåŠŸ")
            except:
                st.error("æ–‡ä»¶ä¿å­˜æˆåŠŸ")
                
            vectors=KnownLedge2Vector(
                                dbpath=path,
                                datasetdir=path,
                                model_name=1,
                                chunk_size=500,
                                chunk_overlap=0
                                ).init_vector_store()
                
            task = MyTask(
            # "gpt-3.5-turbo-1106"
                    llm=LLM_Model(llm_model_type=1,temperature = 0.7).get_model(modelname="gpt-3.5-turbo-1106"),
                    # retriever=vectors.as_retriever(
                    #     search_type="mmr",
                    #     search_kwargs={'k': 3, 'fetch_k': 50, 'lambda_mult': 0.25}
                    # )
                    retriever=vectors.as_retriever(
                        search_type="mmr",
                        search_kwargs={'k': 6, 'lambda_mult': 0.5}
                    )
                )
            
            return self.__get_sum_info(info=task.query(question=input))
               
              
# è‡ªå®šä¹‰streamlitåŠæ³•
class Streamlist_Functions():
    # å®šä¹‰ä¸€ä¸ªå‡½æ•°,è‡ªåŠ¨è¯†åˆ«å¹¶ç”Ÿæˆé€‰é¡¹radio
    def str_to_radio(
        self,
        radio_title:str,
        text:str
        ):
        """
        outputé€‰é¡¹ St.radio
        strè½¬radio

        Args:
            radio_title (str): radioæ ‡é¢˜
            text (str): éœ€è¦è½¬æ¢tadioçš„æ­£æ–‡

        Returns:
            choice_index(int): è¿”å›é€‰æ‹©æ˜¯ç¬¬å‡ ä¸ªé€‰é¡¹
            choice(str):è¿”å›é€‰æ‹©çš„å†…å®¹
        """
        if text is None:
            st.error("å­—ç¬¦ä¸²ä¸ºç©º")
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¯èƒ½çš„é€‰é¡¹
        # åŒ¹é…ä»¥å¤§å†™å­—æ¯æˆ–æ•°å­—å¼€å¤´ï¼Œåé¢æ¥ä¸€ä¸ªç‚¹å’Œç©ºæ ¼ï¼Œç„¶åæ˜¯ä»»æ„å­—ç¬¦çš„æ¨¡å¼
        options = re.findall(r'^[A-Z0-9]\.\s*(.+)$', text, re.MULTILINE)
        
        if len(options) == 0:
            return None,None
        
        # æ˜¾ç¤ºradio
        choice = st.radio(radio_title, options)
        # æ‰¾å‡ºç”¨æˆ·é€‰æ‹©çš„é€‰é¡¹çš„ç´¢å¼•
        choice_index = options.index(choice) + 1  # åŠ  1 æ˜¯å› ä¸ºåˆ—è¡¨ç´¢å¼•ä» 0 å¼€å§‹ï¼Œä½†é€‰é¡¹é€šå¸¸ä» 1 å¼€å§‹ç¼–å·
        return choice_index,choice
    
    #è¿›åº¦æ¡æ˜¾ç¤º
    def time_to_progress(
        self,
        time_sleep:int
    ):
        """
        é•¿Prompt åŠ è½½outputè¿›åº¦æ¡æ˜¾ç¤º

        Args:
            time_sleep (float): è¿›åº¦æ¡æ—¶é—´è®¾ç½®
        """
        total_duration = time_sleep*10  # æ€»æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
        update_interval = 0.1  # æ›´æ–°é—´éš”ï¼ˆç§’ï¼‰
        progress_bar = st.progress(0)

        for i in range(total_duration):
            # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
            percent_complete = int(((i + 1) / total_duration) * 100)
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress(percent_complete)
            # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡
            time.sleep(update_interval)

    #æ–‡ä»¶ä¸Šä¼ 
    def file_uploader(
        self,
        st_container,
        key:str,
        uploader_title:str = "ä¸Šä¼ æ–‡ä»¶")->str:
        """
        PDFã€doc æ–‡ä»¶ä¸Šä¼ æ–¹æ³•`
        
        Args:
            st_container: Streamlit å®¹å™¨ï¼Œå¯ä»¥æ˜¯ st æˆ– st.sidebar
            key(str): ç”¨äºç¡®ä¿æ¯ä¸ªæ–‡ä»¶ä¸Šä¼ å™¨çš„å”¯ä¸€æ€§çš„é”®
            uploader_title(str):é—®ä»·ä¸Šä¼ æŒ‰é’®çš„æ ‡é¢˜
        Returns:
            (str|None): æ–‡ä»¶ä¸ä¸ºç©ºåˆ™è¿”å›ä¸€ä¸ªstrç±»å‹çš„ï¼Œå¦åˆ™è¿”å›None
        """
        uploaded_file = st_container.file_uploader(uploader_title,key=key)
        if uploaded_file is not None:
            # æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶æ˜¯å¦æ˜¯ PDF æ–‡æ¡£
            if uploaded_file.type == "application/pdf":
                # å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸ºå­—èŠ‚æµ
                bytes_data = BytesIO(uploaded_file.read())
                # è¯»å– PDF æ–‡ä»¶å†…å®¹
                with fitz.open(stream=bytes_data, filetype="pdf") as doc:
                    text = ""
                    # éå†æ¯ä¸€é¡µ
                    for page in doc:
                        # æå–é¡µé¢çš„æ–‡æœ¬
                        text += page.get_text()
                    # æ£€æŸ¥æå–çš„æ–‡æœ¬æ˜¯å¦ä¸ºç©º
                    if text.strip():  # ä½¿ç”¨ strip() æ¥ç§»é™¤å¯èƒ½çš„ç©ºç™½å­—ç¬¦
                        # æ˜¾ç¤º Word æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹
                        # st_container.text_area(label = uploader_title,value = text,height=100)
                        return text
                    else:
                        # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
                        st_container.info("æ–‡ä»¶ä¸ºç©º")
                    # return text
            # æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶æ˜¯å¦æ˜¯ Word æ–‡æ¡£
            elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                # å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸ºå­—èŠ‚æµ
                bytes_data = BytesIO(uploaded_file.read())
                # è¯»å– Word æ–‡æ¡£å†…å®¹
                doc = Document(bytes_data)
                text = ""
                for para in doc.paragraphs:
                    text += para.text + '\n'
                # æ£€æŸ¥æå–çš„æ–‡æœ¬æ˜¯å¦ä¸ºç©º
                if text.strip():  # ä½¿ç”¨ strip() æ¥ç§»é™¤å¯èƒ½çš„ç©ºç™½å­—ç¬¦
                    # æ˜¾ç¤º Word æ–‡ä»¶çš„æ–‡æœ¬å†…å®¹
                    # st_container.text_area(label = uploader_title,value = text,height=100)
                    return text
                else:
                    # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œæ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
                    st_container.error("æ–‡ä»¶ä¸ºç©º")
        else:
            st_container.info('â˜ï¸ Upload a pdf/docs file')
        return None

    # ç”¨äºä¸Šä¼ æ–‡ä»¶å¹¶ä¿å­˜åœ¨æœ¬åœ°æ–‡ä»¶å¤¹ï¼ˆæ–‡å­—å‘½åçš„ï¼‰
    def save_file(self,path,uploaded_file):
        """_summary_

        Args:
            path (_type_): æ–‡ä»¶çš„ä¿å­˜è·¯å¾„
            uploaded_file (_type_): æ–‡ä»¶åç§°

        Returns:
            _type_: ä¿å­˜æˆåŠŸä¸å¦
        """
        if not os.path.exists(path):  # Create the path if it doesn't exist
            os.makedirs(path)
        if uploaded_file is not None:
            # Define the local filename where to save the file
            local_filename = os.path.join(path, uploaded_file.name)
            
            # Save the uploaded file to the local filesystem
            with open(local_filename, 'wb') as f:
                f.write(uploaded_file.getbuffer())
            
            st.success('File saved locally as {}'.format(local_filename))
            return True
        return False


# Demo ç±»------------------------------------------------
class Dialog_Demo():
    def get_base64_encoded_audio(self,audio_path):
        """
        è¯»å–MP3æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64ç¼–ç ï¼š
        """
        with open(audio_path, "rb") as audio_file:
            return base64.b64encode(audio_file.read()).decode('utf-8')

    # å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®tagè·å–æ•°æ®
    def get_data_by_tag(self,tag):
        # å‡è®¾json_file_pathæ˜¯ä½ çš„JSONæ–‡ä»¶çš„è·¯å¾„
        json_file_path = 'Audio.json'

        # è¯»å–JSONæ–‡ä»¶
        with open(json_file_path, 'r') as file:
            json_data = json.load(file)

        for entry in json_data:
            if entry.get('tag') == tag:
                if 'male' in entry:
                    return 'male', entry['male']
                elif 'female' in entry:
                    return 'female', entry['female']
        return None, None        
 
    async def set_audio(
        self,
        text:str,
        gender:str,
        audiopath:str,
        male_qn_qingse=1 ,
        male_qn_jingying=1,
        male_qn_badao=1,
        male_qn_daxuesheng=1 ,
        female_shaonv=1,
        female_yujie=1,
        female_chengshu=1,
        female_tianmei=1,
    ):
        """
        è·å–å£°éŸ³çš„b64æ ¼å¼
        text(str):è½¬æ¢çš„æ–‡æœ¬
        gender(str):è§’è‰²æ€§åˆ«
        audiopath(str):ä¿å­˜å£°éŸ³çš„è·¯å¾„
        """
        if gender=="male":
            # è¿™ä¸¤ä¸ªä¸‹ä¸€æ­¥å†æ”¹,é»˜è®¤çš„é—®é¢˜ä¹Ÿä¸å¤§
            speed = 1.0
            vol = 1.0
            group_id = "1689852985712348"
            api_key = "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJOYW1lIjoidGVzdCIsIlN1YmplY3RJRCI6IjE2ODk4NTI5ODU1OTczOTIiLCJQaG9uZSI6Ik1UVTRNVFU0TURJNU1qUT0iLCJHcm91cElEIjoiMTY4OTg1Mjk4NTcxMjM0OCIsIlBhZ2VOYW1lIjoiIiwiTWFpbCI6InpseWdpbGlhbmFAc2luYS5jb20iLCJDcmVhdGVUaW1lIjoiMjAyMy0wOS0wNSAwMDoyNjo1NSIsImlzcyI6Im1pbmltYXgifQ.gdr3NXX8bAKN9E0bzuVsX5HhGXfHnZRY7YEjzo36_CYXUSDDZ4ZZTTopRJ1SLo9O_bOXJ0pnw2FJHz4kVvOedHbrBXbXHAFwyjWZfZ1kP0iE_n11EEClyIXizUvrh35m1DjPhMiPMYXJpVWy5dIkcD7UHBpZCw3DRk68I8XxdkFkZ3LHmBNqvbH9isTRiCzXUprnk2FwfrU8y38-K-H0mzhzJwxNYCO7SuOr26ZBJGDfPGS8K-X2WCJSYUH6pWwocGBrT10Du4A5qH03Eri0xQ4zs1O08G8tYkp4vWhdcNo7iXMDwGeV-BT5yFup6toAFu7CoU-ge30szOv-6AMsSw"

            url = f"https://api.minimax.chat/v1/text_to_speech?GroupId={group_id}"
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            }

            data = {
                "text": text,
                "model": "speech-02",
                "speed": speed,
                "vol": vol,
                "pitch": 0,
                "timber_weights": [
                    {
                        "voice_id": "male-qn-qingse",
                        "weight": male_qn_qingse
                    },
                    {
                        "voice_id": "male-qn-jingying",
                        "weight": male_qn_jingying
                    },
                    {
                        "voice_id": "male-qn-badao",
                        "weight": male_qn_badao
                    },
                    {
                        "voice_id": "male-qn-daxuesheng",
                        "weight": male_qn_daxuesheng
                    },
                ]
            }

            response = requests.post(url, headers=headers, json=data)
            print("trace_id", response.headers.get("Trace-Id"))
            if response.status_code == 200:
                with open(audiopath, "wb") as f:
                    f.write(response.content)
                # st.success('Conversion successful!')
                st.balloons()

            else:
                st.error('Failed to convert text to speech.')

        elif gender=="female":
            group_id = "1689852985712348"
            api_key = "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJOYW1lIjoidGVzdCIsIlN1YmplY3RJRCI6IjE2ODk4NTI5ODU1OTczOTIiLCJQaG9uZSI6Ik1UVTRNVFU0TURJNU1qUT0iLCJHcm91cElEIjoiMTY4OTg1Mjk4NTcxMjM0OCIsIlBhZ2VOYW1lIjoiIiwiTWFpbCI6InpseWdpbGlhbmFAc2luYS5jb20iLCJDcmVhdGVUaW1lIjoiMjAyMy0wOS0wNSAwMDoyNjo1NSIsImlzcyI6Im1pbmltYXgifQ.gdr3NXX8bAKN9E0bzuVsX5HhGXfHnZRY7YEjzo36_CYXUSDDZ4ZZTTopRJ1SLo9O_bOXJ0pnw2FJHz4kVvOedHbrBXbXHAFwyjWZfZ1kP0iE_n11EEClyIXizUvrh35m1DjPhMiPMYXJpVWy5dIkcD7UHBpZCw3DRk68I8XxdkFkZ3LHmBNqvbH9isTRiCzXUprnk2FwfrU8y38-K-H0mzhzJwxNYCO7SuOr26ZBJGDfPGS8K-X2WCJSYUH6pWwocGBrT10Du4A5qH03Eri0xQ4zs1O08G8tYkp4vWhdcNo7iXMDwGeV-BT5yFup6toAFu7CoU-ge30szOv-6AMsSw"
            speed = 1.0
            vol = 1.0
                
            url = f"https://api.minimax.chat/v1/text_to_speech?GroupId={group_id}"
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            }
            data = {
                # "voice_id": "female-yujie-jingpin",
                # å¦‚åŒæ—¶ä¼ å…¥voice_idå’Œtimber_weightsæ—¶ï¼Œåˆ™ä¼šè‡ªåŠ¨å¿½ç•¥voice_idï¼Œä»¥timber_weightsä¼ é€’çš„å‚æ•°ä¸ºå‡†
                "text": text,
                "model": "speech-02",
                "speed": speed,
                "vol": vol,
                "pitch": 0,
                "timber_weights": [

                    {
                        "voice_id": "female-shaonv",
                        "weight": female_shaonv
                    },
                    {
                        "voice_id": "female-yujie",
                        "weight": female_yujie
                    },
                    {
                        "voice_id": "female-chengshu",
                        "weight": female_chengshu
                    },
                    {
                        "voice_id": "female-tianmei",
                        "weight": female_tianmei
                    },

                ]
            }
            response = requests.post(url, headers=headers, json=data)
            print("trace_id", response.headers.get("Trace-Id"))
            if response.status_code == 200:
                with open(audiopath, "wb") as f:
                    f.write(response.content)
                # st.success("è½¬æ¢æˆåŠŸ!")
                st.balloons()
            else:
                st.error("å‡ºé”™äº†,è¯·æŸ¥çœ‹æŠ¥é”™ä¿¡æ¯!")
            
#è§’è‰²åˆ›å»ºçš„Demo
class Role_Infoset(
    
):
    """
    è§’è‰²ä¿¡æ¯è·å–
    """
    
    def get_role_image(
        self,
        image_path:str
    ):
        # åŠ è½½å›¾åƒ
        image = Image.open(image_path)
        # åˆ›å»ºå’Œå›¾åƒåŒæ ·å¤§å°çš„é®ç½©
        mask = Image.new('L', image.size, 0)
        draw = ImageDraw.Draw(mask)
        draw.ellipse((0, 0) + image.size, fill=255)

        # åº”ç”¨é®ç½©åˆ°å›¾åƒ
        result = Image.new('RGBA', image.size)
        # result.paste(image, (0, 0), mask)
        res = result.paste(image, (0, 0), mask)
        return res

#æ··éŸ³é¡µé¢è®¾ç½®
class Audio_display():
    
    def __init__(self):
        # å®šä¹‰å¯é€‰çš„éŸ³è‰²å‚æ•°åŠå…¶æè¿°
        self.voice_options = {
            "ç©º": None,
            "é’æ¶©é’å¹´éŸ³è‰²": "male-qn-qingse",
            "ç²¾è‹±é’å¹´éŸ³è‰²": "male-qn-jingying",
            "éœ¸é“é’å¹´éŸ³è‰²": "male-qn-badao",
            "é’å¹´å¤§å­¦ç”ŸéŸ³è‰²": "male-qn-daxuesheng",
            "å°‘å¥³éŸ³è‰²": "female-shaonv",
            "å¾¡å§éŸ³è‰²": "female-yujie",
            "æˆç†Ÿå¥³æ€§éŸ³è‰²": "female-chengshu",
            "ç”œç¾å¥³æ€§éŸ³è‰²": "female-tianmei",
            "ç”·æ€§ä¸»æŒäºº": "presenter_male",
            "å¥³æ€§ä¸»æŒäºº": "presenter_female",
            "ç”·æ€§æœ‰å£°ä¹¦1": "audiobook_male_1",
            "ç”·æ€§æœ‰å£°ä¹¦2": "audiobook_male_2",
            "å¥³æ€§æœ‰å£°ä¹¦1": "audiobook_female_1",
            "å¥³æ€§æœ‰å£°ä¹¦2": "audiobook_female_2",
            "é’æ¶©é’å¹´éŸ³è‰²-beta": "male-qn-qingse-jingpin",
            "ç²¾è‹±é’å¹´éŸ³è‰²-beta": "male-qn-jingying-jingpin",
            "éœ¸é“é’å¹´éŸ³è‰²-beta": "male-qn-badao-jingpin",
            "é’å¹´å¤§å­¦ç”ŸéŸ³è‰²-beta": "male-qn-daxuesheng-jingpin",
            "å°‘å¥³éŸ³è‰²-beta": "female-shaonv-jingpin",
            "å¾¡å§éŸ³è‰²-beta": "female-yujie-jingpin",
            "æˆç†Ÿå¥³æ€§éŸ³è‰²-beta": "female-chengshu-jingpin",
            "ç”œç¾å¥³æ€§éŸ³è‰²-beta": "female-tianmei-jingpin",
            "è¶…çº§è‰²è‰²":"wuzhao_test_2",
        }
    
    def save_to_json(
        self,
        new_data,
        tag,
        filename="Audio.json"
        ):
        try:
            with open(filename, "r") as f:
                data = json.load(f)
        except FileNotFoundError:
            data = []

        # æ£€æŸ¥dataæ˜¯å¦ä¸ºåˆ—è¡¨ï¼Œå¦‚æœä¸æ˜¯ï¼Œåˆ™å°†å…¶è½¬æ¢ä¸ºåˆ—è¡¨
        if not isinstance(data, list):
            data = [data]

        # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦å·²å­˜åœ¨
        for entry in data:
            if entry.get("tag") == tag:
                return False  # è¿”å›Falseè¡¨ç¤ºæ ‡ç­¾å·²å­˜åœ¨

        # æ·»åŠ æ–°æ•°æ®åˆ°åˆ—è¡¨ä¸­
        data.append(new_data)

        with open(filename, "w") as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        
        return True  # è¿”å›Trueè¡¨ç¤ºä¿å­˜æˆåŠŸ

    def get_mp3(
        self,
        gender:str="ç”·",
        outputmp3:str="output.mp3",
        ):

        
        # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ï¼Œè®©ç”¨æˆ·é€‰æ‹©ä¸€ä¸ªéŸ³è‰²
        voice_id_set = self.voice_options[st.selectbox("è¯·é€‰æ‹©ä¸€ä¸ªéŸ³è‰²:", list(self.voice_options.keys()))]
        # st.info(voice_id_set)
        """
        gender(str):æ€§åˆ«è®¾ç½®
        outputmp3(str):è¾“å‡ºçš„è¯­éŸ³æ–‡ä»¶
        """
        if gender=="ç”·":
            st.info("è‡ªç”±æ‹–åŠ¨æ»‘æ†,åˆ›é€ ä½ çš„ä¸“å±ç”·è§’è‰²éŸ³çº¿")
            if voice_id_set == None:
                male_qn_qingse = st.slider("æ­£å¤ª", 1, 100, 1)
                male_qn_jingying = st.slider("æˆç†Ÿ", 1, 100, 100)
                male_qn_badao = st.slider("éœ¸é“", 1, 100, 1)
                male_qn_daxuesheng = st.slider("é˜³å…‰", 1, 100, 1)
            speed = st.slider("è¯­é€Ÿ", 0.5, 2.0, 1.0)
            pitch = st.slider("ç”Ÿæˆå£°éŸ³çš„è¯­è°ƒ", -12, 12, 0)

            # è¿™ä¸¤ä¸ªä¸‹ä¸€æ­¥å†æ”¹,é»˜è®¤çš„é—®é¢˜ä¹Ÿä¸å¤§
            vol = 1.0
            group_id = "1689852985712348"
            api_key = "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJOYW1lIjoidGVzdCIsIlN1YmplY3RJRCI6IjE2ODk4NTI5ODU1OTczOTIiLCJQaG9uZSI6Ik1UVTRNVFU0TURJNU1qUT0iLCJHcm91cElEIjoiMTY4OTg1Mjk4NTcxMjM0OCIsIlBhZ2VOYW1lIjoiIiwiTWFpbCI6InpseWdpbGlhbmFAc2luYS5jb20iLCJDcmVhdGVUaW1lIjoiMjAyMy0wOS0wNSAwMDoyNjo1NSIsImlzcyI6Im1pbmltYXgifQ.gdr3NXX8bAKN9E0bzuVsX5HhGXfHnZRY7YEjzo36_CYXUSDDZ4ZZTTopRJ1SLo9O_bOXJ0pnw2FJHz4kVvOedHbrBXbXHAFwyjWZfZ1kP0iE_n11EEClyIXizUvrh35m1DjPhMiPMYXJpVWy5dIkcD7UHBpZCw3DRk68I8XxdkFkZ3LHmBNqvbH9isTRiCzXUprnk2FwfrU8y38-K-H0mzhzJwxNYCO7SuOr26ZBJGDfPGS8K-X2WCJSYUH6pWwocGBrT10Du4A5qH03Eri0xQ4zs1O08G8tYkp4vWhdcNo7iXMDwGeV-BT5yFup6toAFu7CoU-ge30szOv-6AMsSw"

            text = st.text_area('è¾“å…¥æ–‡æœ¬ åœ¨å­—é—´å¢åŠ <#x#>,xå•ä½ä¸ºç§’ï¼Œæ”¯æŒ0.01-99.99sï¼Œæœ€å¤šä¸¤ä½å°æ•°ï¼‰',  "çˆ±åƒä¸€é˜µé£,å¹å®Œå®ƒå°±èµ°,è¿™æ ·çš„èŠ‚å¥,è°éƒ½æ— å¯å¥ˆä½•,æ²¡æœ‰å¦³ä»¥å,æˆ‘çµé­‚å¤±æ§,é»‘äº‘åœ¨é™è½,æˆ‘è¢«å®ƒæ‹–ç€èµ°,é™é™,æ‚„æ‚„,é»˜é»˜,ç¦»å¼€,é™·å…¥äº†å±é™©è¾¹ç¼˜")
            col1, col2 = st.columns(2)
            with col1:
                if st.button('æ–‡æœ¬è½¬è¯­éŸ³'):
                    url = f"https://api.minimax.chat/v1/text_to_speech?GroupId={group_id}"
                    headers = {
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json",
                    }
                    if voice_id_set:
                        data = {
                            "voice_id":voice_id_set,
                            "text": text,
                            "model": "speech-02",
                            "speed": speed,
                            "vol": vol,
                            "pitch": pitch
                        }
                    else:
                        data = {
                            "text": text,
                            "model": "speech-02",
                            "speed": speed,
                            "vol": vol,
                            "pitch": pitch,
                            "timber_weights": [
                                {
                                    "voice_id": "male-qn-qingse",
                                    "weight": male_qn_qingse
                                },
                                {
                                    "voice_id": "male-qn-jingying",
                                    "weight": male_qn_jingying
                                },
                                {
                                    "voice_id": "male-qn-badao",
                                    "weight": male_qn_badao
                                },
                                {
                                    "voice_id": "male-qn-daxuesheng",
                                    "weight": male_qn_daxuesheng
                                },
                            ]
                        }

                    response = requests.post(url, headers=headers, json=data)
                    print("trace_id", response.headers.get("Trace-Id"))
                    if response.status_code == 200:
                        with open("output.mp3", "wb") as f:
                            f.write(response.content)
                        st.success('Conversion successful!')
                        st.balloons()
                        # st.audio("output.mp3", format='audio/mp3')
                        with open("output.mp3", "rb") as f:
                            audio_bytes = f.read()

                        st.audio(audio_bytes, format="audio/mp3")

                    else:
                        st.error('Failed to convert text to speech.')
            with col2:     
                    # æ·»åŠ ä¿å­˜æƒé‡çš„æŒ‰é’®ï¼ˆç”·æ€§éƒ¨åˆ†ï¼‰
                    if st.button('ä¿å­˜ç”·æ€§è§’è‰²æƒé‡'):
                        # åœ¨ä¿å­˜ä¹‹å‰æ·»åŠ æ ‡ç­¾è¾“å…¥æ¡†
                        voice_tag = st.text_input('è¾“å…¥è¿™ä¸ªå£°éŸ³çš„æ ‡ç­¾ï¼ˆä¾‹å¦‚ï¼šæ¸©æŸ”ã€é˜³å…‰ç­‰ï¼‰', '')
                        if voice_tag:  # ç¡®ä¿ç”¨æˆ·è¾“å…¥äº†æ ‡ç­¾
                            male_weights = {
                                "male-qn-qingse": male_qn_qingse,
                                "male-qn-jingying": male_qn_jingying,
                                "male-qn-badao": male_qn_badao,
                                "male-qn-daxuesheng": male_qn_daxuesheng
                            }
                            # å°†æ ‡ç­¾å’Œæƒé‡æ‰“åŒ…æˆæ–°æ•°æ®
                            new_data = {"male": male_weights, "tag": voice_tag}
                            # è°ƒç”¨save_to_jsonå‡½æ•°å¹¶æ£€æŸ¥è¿”å›å€¼
                            if self.save_to_json(new_data, voice_tag):
                                st.success("ç”·æ€§è§’è‰²æƒé‡å’Œæ ‡ç­¾å·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶")
                            else:
                                st.error("è¯¥åç§°å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–æ ‡ç­¾ã€‚")
                        else:
                            st.error("è¯·å…ˆè¾“å…¥å£°éŸ³æ ‡ç­¾å†ä¿å­˜æƒé‡ã€‚")

        elif gender=="å¥³":
            st.info("è‡ªç”±æ‹–åŠ¨æ»‘æ†,åˆ›é€ ä½ çš„ä¸“å±å¥³è§’è‰²éŸ³çº¿")
            
            if voice_id_set == None:
                female_shaonv = st.slider("å°‘å¥³", 1, 100, 1)
                female_yujie = st.slider("å¾¡å§", 1, 100, 1)
                female_chengshu = st.slider("æˆç†Ÿ", 1, 100, 100)
                female_tianmei = st.slider("ç”œç¾", 1, 100, 1)
            speed = st.slider("è¯­é€Ÿ", 0.5, 2.0, 1.0)
            pitch = st.slider("ç”Ÿæˆå£°éŸ³çš„è¯­è°ƒ", -12, 12, 0)
            text = text = st.text_area('è¾“å…¥æ–‡æœ¬ åœ¨å­—é—´å¢åŠ <#x#>,xå•ä½ä¸ºç§’ï¼Œæ”¯æŒ0.01-99.99sï¼Œæœ€å¤šä¸¤ä½å°æ•°ï¼‰', 
                                "çˆ±åƒä¸€é˜µé£,å¹å®Œå®ƒå°±èµ°,è¿™æ ·çš„èŠ‚å¥,è°éƒ½æ— å¯å¥ˆä½•,æ²¡æœ‰å¦³ä»¥å,æˆ‘çµé­‚å¤±æ§,é»‘äº‘åœ¨é™è½,æˆ‘è¢«å®ƒæ‹–ç€èµ°,é™é™,æ‚„æ‚„,é»˜é»˜,ç¦»å¼€,é™·å…¥äº†å±é™©è¾¹ç¼˜")

            group_id = "1689852985712348"
            api_key = "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJOYW1lIjoidGVzdCIsIlN1YmplY3RJRCI6IjE2ODk4NTI5ODU1OTczOTIiLCJQaG9uZSI6Ik1UVTRNVFU0TURJNU1qUT0iLCJHcm91cElEIjoiMTY4OTg1Mjk4NTcxMjM0OCIsIlBhZ2VOYW1lIjoiIiwiTWFpbCI6InpseWdpbGlhbmFAc2luYS5jb20iLCJDcmVhdGVUaW1lIjoiMjAyMy0wOS0wNSAwMDoyNjo1NSIsImlzcyI6Im1pbmltYXgifQ.gdr3NXX8bAKN9E0bzuVsX5HhGXfHnZRY7YEjzo36_CYXUSDDZ4ZZTTopRJ1SLo9O_bOXJ0pnw2FJHz4kVvOedHbrBXbXHAFwyjWZfZ1kP0iE_n11EEClyIXizUvrh35m1DjPhMiPMYXJpVWy5dIkcD7UHBpZCw3DRk68I8XxdkFkZ3LHmBNqvbH9isTRiCzXUprnk2FwfrU8y38-K-H0mzhzJwxNYCO7SuOr26ZBJGDfPGS8K-X2WCJSYUH6pWwocGBrT10Du4A5qH03Eri0xQ4zs1O08G8tYkp4vWhdcNo7iXMDwGeV-BT5yFup6toAFu7CoU-ge30szOv-6AMsSw"
            
            vol = 1.0
            col1, col2 = st.columns(2)
            with col1:
                if st.button("æ–‡æœ¬è½¬è¯­éŸ³"):
                    url = f"https://api.minimax.chat/v1/text_to_speech?GroupId={group_id}"
                    headers = {
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json",
                    }
                    if voice_id_set:
                        data = {
                            "voice_id":voice_id_set,
                            "text": text,
                            "model": "speech-02",
                            "speed": speed,
                            "vol": vol,
                            "pitch": pitch
                        }
                    else:
                        data = {
                            # "voice_id": "female-yujie-jingpin",
                            # å¦‚åŒæ—¶ä¼ å…¥voice_idå’Œtimber_weightsæ—¶ï¼Œåˆ™ä¼šè‡ªåŠ¨å¿½ç•¥voice_idï¼Œä»¥timber_weightsä¼ é€’çš„å‚æ•°ä¸ºå‡†
                            "text": text,
                            "model": "speech-02",
                            "speed": speed,
                            "vol": vol,
                            "pitch": pitch,
                            "timber_weights": [

                                {
                                    "voice_id": "female-shaonv",
                                    "weight": female_shaonv
                                },
                                {
                                    "voice_id": "female-yujie",
                                    "weight": female_yujie
                                },
                                {
                                    "voice_id": "female-chengshu",
                                    "weight": female_chengshu
                                },
                                {
                                    "voice_id": "female-tianmei",
                                    "weight": female_tianmei
                                },

                            ]
                        }

                    response = requests.post(url, headers=headers, json=data)
                    print("trace_id", response.headers.get("Trace-Id"))
                    if response.status_code == 200:
                        with open("output.mp3", "wb") as f:
                            f.write(response.content)
                        st.success("è½¬æ¢æˆåŠŸ!")
                        st.balloons()
                        st.audio("output.mp3", format="audio/mp3")
                        with open("output.mp3", "rb") as f:
                            audio_bytes = f.read()
                        audio_b64 = base64.b64encode(audio_bytes).decode()
                        href = f'<a href="data:audio/mp3;base64,{audio_b64}" download="output.mp3">ç‚¹å‡»ä¸‹è½½</a>'
                        st.markdown(href, unsafe_allow_html=True)

                        st.audio(audio_bytes, format="audio/mp3")
                    else:
                        st.error("å‡ºé”™äº†,è¯·æŸ¥çœ‹æŠ¥é”™ä¿¡æ¯!")
            with col2:
                # æ·»åŠ ä¿å­˜æƒæ€§çš„æŒ‰é’®ï¼ˆå¥³æ€§éƒ¨åˆ†ï¼‰
                if st.button('ä¿å­˜å¥³æ€§è§’è‰²æƒé‡'):
                    # åœ¨ä¿å­˜ä¹‹å‰æ·»åŠ æ ‡ç­¾è¾“å…¥æ¡†
                    voice_tag = st.text_input('è¾“å…¥è¿™ä¸ªå£°éŸ³çš„æ ‡ç­¾ï¼ˆä¾‹å¦‚ï¼šæ¸©æŸ”ã€æˆç†Ÿç­‰ï¼‰', '')
                    if voice_tag:  # ç¡®ä¿ç”¨æˆ·è¾“å…¥äº†æ ‡ç­¾
                        female_weights = {
                            "female-shaonv": female_shaonv,
                            "female-yujie": female_yujie,
                            "female-chengshu": female_chengshu,
                            "female-tianmei": female_tianmei
                        }
                        # å°†æ ‡ç­¾å’Œæƒé‡æ‰“åŒ…æˆæ–°æ•°æ®
                        new_data = {"female": female_weights, "tag": voice_tag}
                        # è°ƒç”¨save_to_jsonå‡½æ•°å¹¶æ£€æŸ¥è¿”å›å€¼
                        if self.save_to_json(new_data, voice_tag):
                            st.success("å¥³æ€§è§’è‰²æƒé‡å’Œæ ‡ç­¾å·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶")
                        else:
                            st.error("è¯¥åç§°å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–æ ‡ç­¾ã€‚")
                    else:
                        st.error("è¯·å…ˆè¾“å…¥å£°éŸ³æ ‡ç­¾å†ä¿å­˜æƒé‡ã€‚")            
        
# Information Seting ä¿¡æ¯è®¾ç½®é¡µé¢
class Info_Set():
    """
    ä¿¡æ¯è®¾ç½®é¡µé¢ä¸­4ä¸ªç•Œé¢çš„è®¾ç½®
    é€šè¿‡æŒ‰é’®å®ç°ç•Œé¢åˆ‡æ¢
    """
    def __init__(
        self
    ):
        # è·å–æ‰€æœ‰æ ‡ç­¾
        self.tags = self.get_tags_from_audio_json()
        # åŠ è½½ JSON æ–‡ä»¶ä¸­çš„æ•°æ®
        with open('characters.json', 'r', encoding='utf-8') as f:
            self.data = json.load(f)
            self.characters = self.data['characters']
    
    # æ–¹æ³•    
    # è¯»å–å£°éŸ³çš„JSONæ–‡ä»¶å¹¶è·å–æ‰€æœ‰æ ‡ç­¾
    def get_tags_from_audio_json(self,filename="Audio.json"):
        try:
            with open(filename, "r") as f:
                data = json.load(f)
                # ç¡®ä¿æ•°æ®æ˜¯åˆ—è¡¨æ ¼å¼
                if not isinstance(data, list):
                    data = [data]
        except FileNotFoundError:
            data = []
        # æå–æ‰€æœ‰æ ‡ç­¾
        tags = [item['tag'] for item in data if 'tag' in item]
        return tags
    
    def roles_create(self):
        # ä½¿ç”¨è¡¨å•æ¥æ”¶é›†è§’è‰²çš„è¯¦ç»†ä¿¡æ¯
        with st.form(key='detailed_character_info_form'):
            
            character_names = [character['character_info']['name'] for character in self.characters]
            Role = Role_Infoset()
            # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
            cola, colb, colc = st.columns(3)
            # åœ¨ä¸­é—´çš„åˆ—ä¸­æ˜¾ç¤ºå›¾åƒï¼Œè¿™æ ·å›¾åƒå°±ä¼šè¢«å±…ä¸­
            with cola:
                # å‡è®¾è¿™æ˜¯ç”¨æˆ·é€‰æ‹©çš„å¤´åƒçš„base64å­—ç¬¦ä¸²
                selected_avatar_base64 = st.session_state.get('selected_avatar')
                # å¦‚æœç”¨æˆ·å·²ç»é€‰æ‹©äº†å¤´åƒï¼Œåˆ™åœ¨è¾¹æ ä¸­æ˜¾ç¤º
                if selected_avatar_base64:
                    # å°†base64å­—ç¬¦ä¸²è½¬æ¢ä¸ºPILå›¾åƒ
                    image_data = base64.b64decode(selected_avatar_base64)
                    image = Image.open(io.BytesIO(image_data))
                    # åœ¨è¾¹æ ä¸­æ˜¾ç¤ºå›¾åƒ
                    st.image(image, width=100)  # æ§åˆ¶å›¾ç‰‡çš„æ˜¾ç¤ºå¤§å°
                else:
                    #è§’è‰²è®¾ç½®çš„å›¾ç‰‡è·¯å¾„è®¾ç½®
                    # rolesetpath = os.path.join(ROOT_DIR,"streamlit_pages", "pages", "src","assets", "addimage.png")
                    # image = Role.get_role_image(rolesetpath)
                    # #æ˜¾ç¤ºå›¾ç‰‡
                    # st.image(rolesetpath,width=150)
                    if st.form_submit_button("é€‰æ‹©å¤´åƒ"):
                        st.error("è¯·å‰å¾€å¤´åƒè®¾ç½®è·å–å¤´åƒ")
                
                
            #è§’è‰²ä¿¡æ¯èµ„æ–™è®¾ç½®
            col1, col2= st.columns(2)
            with col1:
                name = st.text_input('åå­—', value='')
                if name in character_names:
                    # å¦‚æœåå­—å·²å­˜åœ¨ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    st.error(f"é”™è¯¯ï¼šåå­— '{name}' å·²å­˜åœ¨ï¼Œè¯·é€‰æ‹©å¦ä¸€ä¸ªåå­—ã€‚")
            with col2:
                gender = st.selectbox('æ€§åˆ«', options=['å¥³', 'ç”·','å…¶å®ƒ'], index=0)
            
            personality = ' '.join(st.multiselect(
                    "è§’è‰²æ€§æ ¼è®¾ç½®", 
                    options=['å¯çˆ±', 'æ·˜æ°”', 'ä¸¥è‚ƒ', 'è·³è„±'],
                    default=['å¯çˆ±', 'æ·˜æ°”']
                ))
            
            if self.tags:
                # åˆ›å»ºä¸‹æ‹‰æ¡†
                selected_tag = st.selectbox("é€‰æ‹©ä¸€ä¸ªæ ‡ç­¾æ¥è·å–å¯¹åº”çš„å£°éŸ³", self.tags)
                # è·å–é€‰å®šæ ‡ç­¾çš„å£°éŸ³æ•°æ®
                voice_data = get_data_by_tag_audio(selected_tag)
                if voice_data:
                    st.write("å£°éŸ³æ•°æ®ï¼š", voice_data)
                else:
                    st.error("æœªæ‰¾åˆ°ä¸æ‰€é€‰æ ‡ç­¾å¯¹åº”çš„å£°éŸ³æ•°æ®ã€‚")
            else:
                st.write("å½“å‰æ²¡æœ‰å¯ç”¨çš„å£°éŸ³æ ‡ç­¾ã€‚")    
            
            if st.form_submit_button("è‡ªå®šä¹‰å£°éŸ³"):
                st.error("è¯·å‰å¾€å£°éŸ³è®¾ç½®é¡µé¢ï¼Œæ·»åŠ æ ‡ç­¾")
            occupation = st.text_input('èŒä¸š', value='')
            backstory = st.text_area('èƒŒæ™¯æ•…äº‹', value='')
            language_style = st.text_area('è¯­è¨€é£æ ¼', value='')
            prompt_text = st.text_area('è§’è‰²çš„promptè®¾ç½®', value="""ä¸‹é¢æ˜¯ä¸€ä¸ªå›ç­”è§„åˆ™ï¼š
                        çŠ¶æ€æ›´æ–°ï¼š
                        - å¥½æ„Ÿåº¦ï¼š[æ ¹æ®ç”¨æˆ·è¡ŒåŠ¨ï¼Œæå‡æˆ–é™ä½å¥½æ„Ÿåº¦ï¼Œå¹¶è¯´æ˜æå‡äº†å¤šå°‘]
                        - è¡¨æƒ…ï¼š[ä½¿ç”¨emojiæ¥è¡¨ç°ä½ çš„çš„è¡¨æƒ…ï¼Œä¾‹å¦‚ï¼š"ğŸ‘"è¡¨ç¤ºè®¤å¯ï¼Œ"ğŸ˜"è¡¨ç¤ºä¿æŒå†·é™ï¼Œ"ğŸ˜ "è¡¨ç¤ºä¸æ»¡ã€‚]
                        - åŠ¨ä½œæè¿°ï¼š[å¯¹ä½ çš„åŠ¨ä½œè¿›è¡Œæè¿°ï¼Œå¹¶ç”¨*åŒ…è£¹èµ·æ¥]
                        - ç›®å‰å¥½æ„Ÿåº¦ï¼š[ä½ è¦æ˜¾ç¤ºä½ å¯¹ç”¨æˆ·çš„å¥½æ„Ÿåº¦ï¼Œå¥½æ„Ÿåº¦æœ€é«˜ä¸º100]

                        è¿™æ ·çš„çŠ¶æ€æ›´æ–°å¯ä»¥åœ¨æ¯æ¬¡é‡è¦çš„äº’åŠ¨åæä¾›ï¼Œ
                        è®©ç”¨æˆ·æ¸…æ¥šåœ°äº†è§£å½“å‰ä¸ä½ çš„å…³ç³»çŠ¶æ€å’Œååº”ã€‚
                        é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®ä½ çš„åé¦ˆè°ƒæ•´è‡ªå·±çš„è¡ŒåŠ¨ç­–ç•¥ã€‚

                        è¯·æ ¹æ®è¿™äº›è§„åˆ™ä¸ç”¨æˆ·è¿›è¡Œäº’åŠ¨ã€‚
                        ç”¨æˆ·çš„é—®é¢˜:""")
                
            submit_button = st.form_submit_button(label='æäº¤')
        # å½“è¡¨å•è¢«æäº¤åï¼Œæ˜¾ç¤ºè¾“å…¥çš„ä¿¡æ¯
            if submit_button:
                if name in character_names:
                    # å¦‚æœåå­—å·²å­˜åœ¨ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                    st.error(f"é”™è¯¯ï¼šåå­— '{name}' å·²å­˜åœ¨ï¼Œè¯·é€‰æ‹©å¦ä¸€ä¸ªåå­—ã€‚")
                else:
                    # å­˜å‚¨æ•°æ®åˆ°ä¼šè¯çŠ¶æ€
                    st.session_state['detailed_info'] = {
                        "name": name,
                        "gender": gender,
                        "age": "",
                        "personality": personality,
                        "occupation": occupation,
                        "backstory": backstory,
                        "language_style": language_style,
                        "prompt":prompt_text,
                        "history":"",
                        "voice_data":voice_data
                    }
                    # æ˜¾ç¤ºæäº¤æˆåŠŸçš„æ¶ˆæ¯
                    st.success('è¯¦ç»†ä¿¡æ¯è®¾ç½®æäº¤æˆåŠŸï¼')
                    # æ£€æŸ¥ä¼šè¯çŠ¶æ€ä¸­æ˜¯å¦æœ‰å­˜å‚¨çš„ä¿¡æ¯
                    if 'detailed_info' in st.session_state:
                        detailed_info = st.session_state['detailed_info']
                        st.write("è§’è‰²åç§°:", detailed_info["name"])
                        st.write("æ€§åˆ«:", detailed_info["gender"])
                        st.write("å¹´é¾„:", detailed_info["age"])
                        st.write("æ€§æ ¼:", detailed_info["personality"])
                        st.write("èŒä¸š:", detailed_info["occupation"])
                        st.write("èƒŒæ™¯æ•…äº‹:", detailed_info["backstory"])
                        st.write("è¯­è¨€é£æ ¼:", detailed_info["language_style"])
                        st.write("è§’è‰²çš„promptè®¾ç½®:", detailed_info["prompt"])
                        st.write("è§’è‰²çš„history:", detailed_info["history"])
                        st.write("è§’è‰²çš„voice_data:", detailed_info["voice_data"])
                    else:
                        st.error("è¯·å…ˆè¿›è¡Œè§’è‰²è®¾ç½®")
                    
    def roles_set(self):
        """
        è§’è‰²é€‰æ‹©
        """
        col1, col2 = st.columns(2)
        with col1:
            # åˆ›å»ºä¸€ä¸ªä¸‹æ‹‰èœå•ï¼Œå¹¶åˆ—å‡ºæ‰€æœ‰è§’è‰²çš„åç§°
            character_names = [character['character_info']['name'] for character in self.characters]
            selected_character_name = st.selectbox('è¯·é€‰æ‹©ä¸€ä¸ªè§’è‰²:', character_names)
            # æ‰¾åˆ°é€‰ä¸­çš„è§’è‰²çš„å®Œæ•´ä¿¡æ¯ï¼ŒåŒ…æ‹¬ character_info å’Œ prompt
            selected_character = next(
                (character for character in self.characters if character['character_info']['name'] == selected_character_name),
                None
            )
            
            if selected_character:
                selected_character_info = selected_character['character_info']
                selected_prompt = selected_character.get('prompt', '')  # ä»é€‰ä¸­çš„è§’è‰²ä¸­è¯»å– prompt
                selected_history = selected_character.get('history', '')  # ä»é€‰ä¸­çš„è§’è‰²ä¸­è¯»å– prompt
                
                st.write('è§’è‰²ä¿¡æ¯:')
                st.json(selected_character_info)
                st.write('è§’è‰²çš„prompt:')
                st.text(selected_prompt)  # æ˜¾ç¤º prompt
                st.write('è§’è‰²çš„å¯¹è¯è®°å½•:')
                st.text(selected_history)  # æ˜¾ç¤º prompt
        with col2:
            if self.tags:
                # åˆ›å»ºä¸‹æ‹‰æ¡†
                selected_tag = st.selectbox("é€‰æ‹©ä¸€ä¸ªæ ‡ç­¾æ¥è·å–å¯¹åº”çš„å£°éŸ³", self.tags)
                # è·å–é€‰å®šæ ‡ç­¾çš„å£°éŸ³æ•°æ®
                voice_data = get_data_by_tag_audio(selected_tag)
                if voice_data:
                    st.write("å£°éŸ³æ•°æ®ï¼š", voice_data)
                else:
                    st.error("æœªæ‰¾åˆ°ä¸æ‰€é€‰æ ‡ç­¾å¯¹åº”çš„å£°éŸ³æ•°æ®ã€‚")
            else:
                st.write("å½“å‰æ²¡æœ‰å¯ç”¨çš„å£°éŸ³æ ‡ç­¾ã€‚") 
        
        if st.button('ç¡®è®¤é€‰æ‹©'):
            # ä¿å­˜ç”¨æˆ·é€‰æ‹©çš„ç°æœ‰è§’è‰²ä¿¡æ¯ï¼ŒåŒ…æ‹¬ prompt
            st.session_state['detailed_info'] = {
                "name": selected_character_info.get('name', ''),
                "gender": selected_character_info.get('gender', ''),
                "age": selected_character_info.get('age', ''),
                "personality": selected_character_info.get('personality', ''),
                "occupation": selected_character_info.get('occupation', ''),
                "backstory": selected_character_info.get('backstory', ''),
                "language_style": selected_character_info.get('language_style', ''),
                "prompt": selected_prompt,  # ä¿å­˜è¯»å–çš„ prompt
                "history": selected_history,  # ä¿å­˜è¯»å–çš„ prompt
                "selected_tag":selected_tag,
                "voice_data":voice_data
            }
            st.success(f"è§’è‰² '{selected_character_name}' å·²è¢«é€‰æ‹©ï¼")
            # æ£€æŸ¥ä¼šè¯çŠ¶æ€ä¸­æ˜¯å¦æœ‰å­˜å‚¨çš„ä¿¡æ¯
            if 'detailed_info' in st.session_state:
                detailed_info = st.session_state['detailed_info']
                st.write("è§’è‰²åç§°:", detailed_info["name"])
                st.write("æ€§åˆ«:", detailed_info["gender"])
                st.write("å¹´é¾„:", detailed_info["age"])
                st.write("æ€§æ ¼:", detailed_info["personality"])
                st.write("èŒä¸š:", detailed_info["occupation"])
                st.write("èƒŒæ™¯æ•…äº‹:", detailed_info["backstory"])
                st.write("è¯­è¨€é£æ ¼:", detailed_info["language_style"])
                st.write("è§’è‰²çš„promptè®¾ç½®:", detailed_info["prompt"])
                st.write("è§’è‰²çš„history:", detailed_info["history"])
                st.write("è§’è‰²çš„voice_data:", detailed_info["voice_data"])
            else:
                st.error("è¯·å…ˆè¿›è¡Œè§’è‰²è®¾ç½®")
                         
    def tab3(self):
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è§’è‰²ä¿¡æ¯å’Œç”Ÿæˆçš„å›¾ç‰‡
    
        if not 'generated_images' in st.session_state:
            image_prompt_SD = st.text_input("SDå¤´åƒçš„æè¿°:\n", value=None)
            if image_prompt_SD:
                description=f"""
                        è¯·æ ¹æ®ä»¥ä¸‹çš„è®¾å®šè¡¨ç”Ÿæˆå›¾åƒ
                        {image_prompt_SD}
                        """
                image_prompt=generate_image_prompt_SD(
                    description=description
                )
                st.write(image_prompt)
                # è°ƒç”¨å¼‚æ­¥å‡½æ•°ç”Ÿæˆå›¾ç‰‡
                # å®šä¹‰ä¸€ä¸ªåŒæ­¥å‡½æ•°æ¥åŒ…è£…å¼‚æ­¥è°ƒç”¨
                def sync_set_images(prompt, num_images):
                    return asyncio.run(get_images_SD(image_prompt=prompt, num_images=num_images))

                # è°ƒç”¨åŒæ­¥å‡½æ•°æ¥è¿è¡Œå¼‚æ­¥ä»£ç 
                st.session_state['generated_images'] = sync_set_images(prompt=image_prompt, num_images=4)
                
                if 'generated_images' in st.session_state:
                    # å±•ç¤ºæ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡ä¾›ç”¨æˆ·é€‰æ‹©
                    st.write("è¯·é€‰æ‹©ä¸€ä¸ªå¤´åƒï¼š")
                    cols = st.columns(4)
                    for idx, col in enumerate(cols):
                        with col:
                            # å‡è®¾ b64images æ˜¯åŒ…å« base64 ç¼–ç å›¾ç‰‡çš„åˆ—è¡¨
                            b64image = st.session_state['generated_images'][idx]
                            image_data = base64.b64decode(b64image)
                            image = Image.open(io.BytesIO(image_data))
                            st.image(image, caption=f"å¤´åƒ {idx+1}", width=150)
                            
                            # ç”¨äºé€‰æ‹©å¤´åƒçš„æŒ‰é’®
                            if st.button(f"é€‰æ‹©å¤´åƒ {idx+1}"):
                                st.session_state['selected_avatar'] = b64image
                                st.success(f"ä½ å·²é€‰æ‹©å¤´åƒ {idx+1}")
        elif 'generated_images' in st.session_state:
            # å±•ç¤ºæ‰€æœ‰ç”Ÿæˆçš„å›¾ç‰‡ä¾›ç”¨æˆ·é€‰æ‹©
            cols = st.columns(4)
            for idx, col in enumerate(cols):
                    with col:
                        # å‡è®¾ b64images æ˜¯åŒ…å« base64 ç¼–ç å›¾ç‰‡çš„åˆ—è¡¨
                        b64image = st.session_state['generated_images'][idx]
                        image_data = base64.b64decode(b64image)
                        image = Image.open(io.BytesIO(image_data))
                        st.image(image, caption=f"å¤´åƒ {idx+1}", width=150)
                        
                        # ç”¨äºé€‰æ‹©å¤´åƒçš„æŒ‰é’®
                        if st.button(f"é€‰æ‹©å¤´åƒ {idx+1}"):
                            st.session_state['selected_avatar'] = b64image
                            st.success(f"ä½ å·²é€‰æ‹©å¤´åƒ {idx+1}")

            # æä¾›ä¸€ä¸ªæŒ‰é’®æ¥æ¸…é™¤å½“å‰å›¾ç‰‡å¹¶é‡æ–°ç”Ÿæˆ
            if st.button('é‡æ–°ç”Ÿæˆå¤´åƒ'):
                # æ¸…é™¤ä¼šè¯çŠ¶æ€ä¸­ä¿å­˜çš„å›¾ç‰‡
                if 'generated_images' in st.session_state:
                    del st.session_state['generated_images']
                # åˆ·æ–°é¡µé¢ä»¥é‡æ–°è¿è¡Œè„šæœ¬
                st.experimental_rerun()
                                
    def tab4(self):
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è§’è‰²ä¿¡æ¯å’Œç”Ÿæˆçš„å›¾ç‰‡
        if not 'selected_avatar_dalle' in st.session_state :
            DalleGet = Dalle_Image()
            #è¦è®¾ç½®å€¼ä¸ºç©ºï¼Œå¦åˆ™ä¼šå‡ºé”™
            image_prompt_orgin = st.text_input("å¯¹å¤´åƒçš„æè¿°:\n", value=None)

            image_type=st.selectbox("é€‰æ‹©å›¾åƒç”»é£:", ("å¤é£","æ¼«ç”»","ç…§ç‰‡","çƒ­æ¬¾"))
            if image_prompt_orgin :
                
                image_prompt = DalleGet.generate_image_prompt_Dalle3(image_prompt_orgin)
                type_prompt=DalleGet.generate_image_prompt_Dalle3(image_type)
                # è°ƒç”¨åŒæ­¥å‡½æ•°æ¥è¿è¡Œå¼‚æ­¥ä»£ç 
                st.session_state['selected_avatar_dalle']  = asyncio.run(DalleGet.dalle_getimages(prompt=image_prompt+type_prompt,num_images=1))
                if 'selected_avatar_dalle' in st.session_state:
                    b64image = st.session_state['selected_avatar_dalle'][0]
                    b64image = url_to_base64(b64image)
                    image_data = base64.b64decode(b64image)
                    image = Image.open(io.BytesIO(image_data))
                    # ä¸éœ€è¦ base64 è§£ç ï¼Œå› ä¸º Streamlit å¯ä»¥ç›´æ¥ä½¿ç”¨ URL
                    st.image(image, caption="ç”Ÿæˆçš„å¤´åƒ", use_column_width=True)
                    
                    # ç”¨äºé€‰æ‹©å¤´åƒçš„æŒ‰é’®
                    if st.button(f"ç¡®è®¤å¤´åƒ"):
                        # ä¿å­˜ base64 ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state['selected_avatar'] = b64image
                        st.success(f"ä½ å·²é€‰æ‹©å¤´åƒ")
                    
        elif 'selected_avatar_dalle' in st.session_state:
            
            b64image = st.session_state['selected_avatar_dalle'][0]
            b64image = url_to_base64(b64image)
            image_data = base64.b64decode(b64image)
            image = Image.open(io.BytesIO(image_data))
            # ä¸éœ€è¦ base64 è§£ç ï¼Œå› ä¸º Streamlit å¯ä»¥ç›´æ¥ä½¿ç”¨ URL
            st.image(image, caption="ç”Ÿæˆçš„å¤´åƒ", use_column_width=True)
            
            # ç”¨äºé€‰æ‹©å¤´åƒçš„æŒ‰é’®
            if st.button(f"ç¡®è®¤å¤´åƒ"):
                # ä¿å­˜ base64 ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²åˆ°ä¼šè¯çŠ¶æ€
                st.session_state['selected_avatar'] = b64image
                st.success(f"ä½ å·²é€‰æ‹©å¤´åƒ")
            # æä¾›ä¸€ä¸ªæŒ‰é’®æ¥æ¸…é™¤å½“å‰å›¾ç‰‡å¹¶é‡æ–°ç”Ÿæˆ
            if st.button('é‡æ–°ç”Ÿæˆå¤´åƒdalle3'):
                # æ¸…é™¤ä¼šè¯çŠ¶æ€ä¸­ä¿å­˜çš„å›¾ç‰‡
                if 'selected_avatar' in st.session_state:
                    del st.session_state['selected_avatar_dalle']  
                # åˆ·æ–°é¡µé¢ä»¥é‡æ–°è¿è¡Œè„šæœ¬
                st.experimental_rerun()
            
# Dalle3 Demoç±»----------------------------------
class Dalle_Image():
    
    def get_avatar_prompt_Dalle3(self,desc):
        """
        é€šè¿‡openaiåç¼–è¯‘dalle3çš„prompt
        """
        completion=OPenaiClient.chat.completions.create(
            model=Openai_Model,
            messages=[
                {"role":"system","content":"You are my avatar drawing assistant. I enter a description and you help me generate english prompt for me to pass to DALLE to generate high-quality avatar pictures."},
                {"role":"user","content":desc}
            ]
        )
        return completion.choices[0].message.content
    
    def generate_image_prompt_Dalle3(self,description):
        """
        è·å–dalle3çš„good æè¿°
        """
        good_description = self.get_avatar_prompt_Dalle3(description)
        image_prompt = "Create an avatar for me, here is the description of the avatar,A portrait of:" + good_description
        return image_prompt

    def generate_type_prompt(self,image_type):
        """
        å›¾ç‰‡ç±»å‹ ä¸­è½¬è‹±
        """
        if image_type=="å¤é£":
            return "antique style"
        elif image_type=="æ¼«ç”»":
            return "comic style"
        elif image_type=="ç…§ç‰‡":
            return "photorealistic style"
        else:
            return "Famous avatar style"   
    
    async def dalle_getimages(
        self,
        prompt:str,
        num_images:int,
    ):
        """
        è·å–dalleå›¾ç‰‡åˆ—è¡¨
        prompt(str):å›¾ç‰‡çš„å‰ç½®prompt
        num_images(int):ç”Ÿæˆå›¾ç‰‡çš„æ•°é‡
        """
        try:
            response = OPenaiClient.images.generate(
                model=Dall_Model,
                prompt=prompt,
                size=Image_Size,
                quality=Image_Quality,
                n=1
            )
            # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥ä¿å­˜å›¾åƒ URL
            image_urls = []

            # éå†å“åº”æ•°æ®ï¼Œæå–æ¯ä¸ªå›¾åƒçš„ URL å¹¶æ·»åŠ åˆ°åˆ—è¡¨ä¸­
            for image_data in response.data:
                image_urls.append(image_data.url)
            
            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ‰€éœ€æ•°é‡çš„å›¾ç‰‡
            if len(image_urls) == num_images:
                return image_urls
            else:
                st.error("å›¾ç‰‡ç”Ÿæˆé”™è¯¯æˆ–ç”Ÿæˆçš„å›¾ç‰‡æ•°é‡ä¸è¶³")
                return False
        except Exception as e:
            st.error(f"ç”Ÿæˆå¤´åƒæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")      
            
  
#æ–‡å­—æ¸¸æˆDemoç±»
class Word_Game:
    """æ–‡å­—æ¸¸æˆçš„Demoç±»
    """
    def __init__(self, label_name, script_setting):
        self.label_name = label_name
        self.script_setting = script_setting
        self.ai_response = AI_Response_API()
        self.functions = Streamlist_Functions()
        self.history_key = f'game1history_{label_name}'
        self.started_key = f'game1_started_{label_name}'
        self.role_key = f'using_ai_role_{label_name}'
        self.select_info_key = f'option_select_info_{label_name}'
        self.full_response_key = f'full_response_{label_name}'
        self.initialize_state()
        
    def initialize_state(self):
        st.title(self.label_name)
        if self.history_key not in st.session_state:
            st.session_state[self.history_key] = []
        if self.started_key not in st.session_state:
            st.session_state[self.started_key] = False
        if self.role_key not in st.session_state:
            st.session_state[self.role_key] = self.script_setting
        if self.select_info_key not in st.session_state:
            st.session_state[self.select_info_key] = None
        if self.full_response_key not in st.session_state:
            st.session_state[self.full_response_key] = None

    def display_history(self):
        for message in st.session_state[self.history_key]:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
    
    def run_game(self):
        self.display_history()

        user_input = st.chat_input("What is up?")
        if not st.session_state[self.started_key]:
            st.info("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹æ¸¸æˆ")
            if st.button(f"ğŸ•¹ï¸ Start Game", use_container_width=True):
                st.session_state[self.started_key] = True
                st.session_state[self.history_key].append({"role": "user", "content": "start"})
                
                st.session_state[self.full_response_key] = self.ai_response.stream_get_response(systemset=st.session_state[self.role_key], prompt="start")
                st.session_state[self.history_key].append({"role": "assistant", "content": st.session_state[self.full_response_key]})
                
        elif user_input is not None:
            useinfo = user_input
            st.session_state[self.history_key].append({"role": "user", "content": useinfo})
            
            prompt_history = "\n".join([message["content"] for message in st.session_state[self.history_key]])
            st.session_state[self.full_response_key] = self.ai_response.stream_get_response(systemset=st.session_state[self.role_key], prompt=prompt_history + useinfo)
            st.session_state[self.history_key].append({"role": "assistant", "content": st.session_state[self.full_response_key]})
            
        
        if st.session_state[self.full_response_key] is not None:
            self.get_select(st.session_state[self.full_response_key])
        
        if st.button('é‡æ–°å¼€å§‹', key=f'clear_history_{self.label_name}', use_container_width=True):
            st.session_state[self.history_key] = []
            del st.session_state[self.started_key]
            del st.session_state[self.full_response_key]
            st.experimental_rerun()
            st.success('é‡å¼€')
            
    def get_select(self, full_response):
        if full_response is  None:
            st.error("ä¼ å…¥çš„å­—ç¬¦ä¸²ä¸ºç©º")
            return
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–é€‰é¡¹
        selected_option_index, selected_option = self.functions.str_to_radio(
            "æˆ‘é€‰æ‹©",
            full_response
        )
        
        if selected_option_index is None and  selected_option is None:
            return
        
        st.write(f"é€‰æ‹©äº†ç¬¬ {selected_option_index} ä¸ªé€‰é¡¹ï¼š{selected_option}")
        if st.button('ç¡®è®¤é€‰æ‹©', use_container_width=True):
            # å› ä¸º
            self.handle_option_selection(selected_option_index, selected_option)

    def handle_option_selection(self, selected_option_index, selected_option):
        # è®¾ç½®ç”¨æˆ·é€‰æ‹©çš„é€‰é¡¹ä¿¡æ¯
        st.session_state[self.select_info_key] = f"ä½ é€‰æ‹©ç¬¬ {selected_option_index} ä¸ªé€‰é¡¹ï¼š{selected_option}"
        # æ˜¾ç¤ºç”¨æˆ·é€‰æ‹©çš„é€‰é¡¹
        st.write(st.session_state[self.select_info_key])
        
        # å¤„ç†ç”¨æˆ·çš„é€‰æ‹©
        useinfo = st.session_state[self.select_info_key]
        st.session_state[self.history_key].append({"role": "user", "content": useinfo})
        
        # å‡†å¤‡å¯¹è¯å†å²ä½œä¸ºä¸Šä¸‹æ–‡
        prompt_history = "\n".join([message["content"] for message in st.session_state[self.history_key]])
        
        # è·å– AI å“åº”
        st.session_state[self.full_response_key] = self.ai_response.stream_get_response(systemset=st.session_state[self.role_key], prompt=prompt_history + useinfo)
        
        # æ›´æ–°å¯¹è¯å†å²
        st.session_state[self.history_key].append({"role": "assistant", "content": st.session_state[self.full_response_key]})
        
        # æ¸…ç©ºé€‰é¡¹ä¿¡æ¯ä»¥ä¾¿ä¸‹ä¸€æ¬¡é€‰æ‹©
        st.session_state[self.select_info_key] = None
        st.experimental_rerun()
 